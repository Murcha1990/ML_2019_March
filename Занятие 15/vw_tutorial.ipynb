{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBcKvo5l7GSj"
   },
   "source": [
    "## Линейные методы. Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oi_m3iyo7GSn"
   },
   "source": [
    "Vowpal Wabbit on GitHub: https://github.com/JohnLangford/vowpal_wabbit\n",
    "\n",
    "Vowpal Wabbit Tutorial: https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "lNecNKWS7INt",
    "outputId": "3b06b940-e9bc-41ea-ae35-b40daabd339f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "vowpal-wabbit is already the newest version (8.5.0.dfsg1-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install vowpal-wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "HB2bBWSY7dqQ",
    "outputId": "6d0de8d6-1acf-49e4-d053-1fa2027798ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-09 09:29:05--  https://www.dropbox.com/s/crld672bipr0n05/train-sample.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:601a:1::a27d:701\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/crld672bipr0n05/train-sample.csv [following]\n",
      "--2019-01-09 09:29:05--  https://www.dropbox.com/s/raw/crld672bipr0n05/train-sample.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc9f3bcb25b1aa2ca12e4d302228.dl.dropboxusercontent.com/cd/0/inline/AZFtkMZg6sY4RvvT4D5zxt4jT91uFxj40qehS3gKcJq5hr0XP-IXFfFeTQmYyusl5QcjUOSVabgT-I6N6cbte-vQw78uE6AfO26OmDr3D85sFfi3k8UhmZ84NJvQe9DPY5ZYHjF6pYusW7SZ7fLXR-LVOkry1MuvAMusEII-FHan-HV91rwRM7H-LoNYsrc92y4/file [following]\n",
      "--2019-01-09 09:29:05--  https://uc9f3bcb25b1aa2ca12e4d302228.dl.dropboxusercontent.com/cd/0/inline/AZFtkMZg6sY4RvvT4D5zxt4jT91uFxj40qehS3gKcJq5hr0XP-IXFfFeTQmYyusl5QcjUOSVabgT-I6N6cbte-vQw78uE6AfO26OmDr3D85sFfi3k8UhmZ84NJvQe9DPY5ZYHjF6pYusW7SZ7fLXR-LVOkry1MuvAMusEII-FHan-HV91rwRM7H-LoNYsrc92y4/file\n",
      "Resolving uc9f3bcb25b1aa2ca12e4d302228.dl.dropboxusercontent.com (uc9f3bcb25b1aa2ca12e4d302228.dl.dropboxusercontent.com)... 162.125.7.6, 2620:100:601b:6::a27d:806\n",
      "Connecting to uc9f3bcb25b1aa2ca12e4d302228.dl.dropboxusercontent.com (uc9f3bcb25b1aa2ca12e4d302228.dl.dropboxusercontent.com)|162.125.7.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 139669798 (133M) [text/plain]\n",
      "Saving to: ‘train-sample.csv?dl=0’\n",
      "\n",
      "train-sample.csv?dl 100%[===================>] 133.20M  63.8MB/s    in 2.1s    \n",
      "\n",
      "2019-01-09 09:29:08 (63.8 MB/s) - ‘train-sample.csv?dl=0’ saved [139669798/139669798]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/crld672bipr0n05/train-sample.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "fwZicsmo7x5R",
    "outputId": "33f4d87b-1b30-4779-e1f4-295d739c690e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " drive\t       train-sample.csv        'train-sample.rar?dl=0'\n",
      " sample_data  'train-sample.csv?dl=0'\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-aEqmcM7GSp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqiyrtOL7GSu"
   },
   "outputs": [],
   "source": [
    "train_path = 'train-sample.csv?dl=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oyK42i_h7GSy",
    "outputId": "b7d043ae-2784-4054-fb42-2815d092d511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(train_path)\n",
    "data.head()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hIe6dY5y7GS4",
    "outputId": "d95f6f13-c8d8-4456-9cdc-1f6224f4366b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open\n",
      "i have two dimensions, first (width, height) and second(width1, height1). how can i retrieve a Point(x,y) from dimensions???\n"
     ]
    }
   ],
   "source": [
    "print(data.OpenStatus[10])\n",
    "print(data.BodyMarkdown[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mnd3r_V47GS9"
   },
   "outputs": [],
   "source": [
    "data_train = data.iloc[:50000, :]\n",
    "data_test = data.iloc[70000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tR2l6tkW7GTA"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def save_to_vw(data, fname):\n",
    "    with open(fname, 'w') as fout:\n",
    "        for _, row in data.iterrows():\n",
    "            text = filter(lambda x: len(x) > 1, re.split(\"[^a-z]\",\n",
    "                                    row.BodyMarkdown.lower()))\n",
    "            text = ' '.join(text)\n",
    "            if row.OpenStatus == \"open\":\n",
    "                target = 1\n",
    "            else:\n",
    "                target = -1\n",
    "            fout.write('{0} |n 0:{1} {2} |t {3}\\n'.format(target, \n",
    "                                        row.ReputationAtPostCreation,\n",
    "                                        row.Tag1,\n",
    "                                        text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBlbJx3C7GTD"
   },
   "outputs": [],
   "source": [
    "save_to_vw(data_train, 'train.vw')\n",
    "save_to_vw(data_test, 'test.vw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Yse2dRCV8-DX",
    "outputId": "303f9ede-3e1c-4a30-8c7d-86a4ffc2f970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " drive\t       test.vw\t\t 'train-sample.csv?dl=0'   train.vw\n",
      " sample_data   train-sample.csv  'train-sample.rar?dl=0'\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "tOjgsuDY7GTG",
    "outputId": "929de2d4-3ca8-459b-f6d9-615807f1eab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 |n 0:1 mongodb |t am building corpus of indexed sentences in different languages have collection of languages which have both an objectid and the iso code as key is it better to use reference to the language collection or store key like en or fr suppose it compromise between ease of referencing the language object in that collection speed in doing queries where the sentence has certain language the size of the data on disk any best practices that should know of\n",
      "1 |n 0:192 dom |t create xml document with jaxp and search way to insert the schemalocation at the moment my application produces xml version encoding utf root root but need xml version encoding utf root xmlns namespaceurl xmlns xs http www org xmlschema instance xs schemalocation namespaceurl pathtomyschema xsd root my code streamresult result new streamresult writer document doc getdocument transformer trans transfac newtransformer trans setoutputproperty outputkeys indent yes trans setoutputproperty outputkeys method xml trans setoutputproperty outputkeys version trans setoutputproperty outputkeys encoding utf domsource source new domsource depl getaselement doc trans transform source result thanks for your time kasten\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "colab_type": "code",
    "id": "TFe67Th17GTM",
    "outputId": "151efe1e-4efc-4283-db65-fe7e41504f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000       81\n",
      "0.500000 0.000000            2            2.0   1.0000   0.7311       98\n",
      "0.906326 1.312652            4            4.0  -1.0000   0.6051      110\n",
      "0.821724 0.737121            8            8.0  -1.0000   0.6143       38\n",
      "0.875065 0.928406           16           16.0   1.0000   0.6741      136\n",
      "0.906826 0.938586           32           32.0   1.0000   0.6249       93\n",
      "0.996030 1.085234           64           64.0   1.0000   0.6714       71\n",
      "0.977266 0.958502          128          128.0  -1.0000   0.4202       24\n",
      "0.990424 1.003582          256          256.0  -1.0000   0.5678       61\n",
      "0.969661 0.948898          512          512.0   1.0000   0.4182       33\n",
      "0.939473 0.909286         1024         1024.0   1.0000   0.4303      189\n",
      "0.933614 0.927755         2048         2048.0  -1.0000   0.3808       24\n",
      "0.915891 0.898169         4096         4096.0  -1.0000   0.6471       38\n",
      "0.900047 0.884203         8192         8192.0  -1.0000   0.4138       16\n",
      "0.849804 0.799560        16384        16384.0   1.0000   0.7311      296\n",
      "0.822175 0.794547        32768        32768.0  -1.0000   0.2689      101\n",
      "0.809638 0.809638        65536        65536.0   1.0000   0.7311      176 h\n",
      "0.808070 0.806503       131072       131072.0  -1.0000   0.3770       10 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 5\n",
      "weighted example sum = 225000.000000\n",
      "weighted label sum = 180.000000\n",
      "average loss = 0.799746 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 24653095\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 --link logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "u-hgdhJH7GTQ",
    "outputId": "4d5f0e6b-2a20-4f89-ff95-8ab2492189df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      187\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      126\n",
      "1.000000 2.000000            4            4.0  -1.0000   0.7311      516\n",
      "0.650943 0.301887            8            8.0   1.0000   0.6917      117\n",
      "0.710289 0.769635           16           16.0   1.0000   0.5795      155\n",
      "0.613725 0.517161           32           32.0   1.0000   0.4811       48\n",
      "0.827658 1.041591           64           64.0  -1.0000   0.7311      226\n",
      "0.809121 0.790584          128          128.0   1.0000   0.5220       86\n",
      "0.811053 0.812985          256          256.0  -1.0000   0.5069       83\n",
      "0.832518 0.853984          512          512.0   1.0000   0.6616      103\n",
      "0.845616 0.858714         1024         1024.0  -1.0000   0.3577       24\n",
      "0.821635 0.797653         2048         2048.0  -1.0000   0.2689      156\n",
      "0.803879 0.786123         4096         4096.0   1.0000   0.7311      167\n",
      "0.812926 0.821974         8192         8192.0  -1.0000   0.4674       45\n",
      "0.809647 0.806369        16384        16384.0  -1.0000   0.4374       81\n",
      "0.808319 0.806991        32768        32768.0  -1.0000   0.6075       66\n",
      "0.805946 0.803573        65536        65536.0   1.0000   0.7311       72\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 70272\n",
      "passes used = 1\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.806739\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 7697580\n"
     ]
    }
   ],
   "source": [
    "!vw -d test.vw -i model.vw -t -p pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "_SUo1dLe7GTT",
    "outputId": "de4fc9e7-6125-4aca-ffad-0ae6f951f94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731059\n",
      "0.731059\n",
      "0.268941\n",
      "0.731059\n",
      "0.520479\n",
      "0.731059\n",
      "0.268941\n",
      "0.691661\n",
      "0.462321\n",
      "0.344321\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6FaIQr2w7GTX",
    "outputId": "1ae2f4af-b8fe-4b2c-8a81-c817e1d91a90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7749402873566568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_vw_qual():\n",
    "    preds = pd.read_csv('pred.txt', header=None).iloc[:, 0].values\n",
    "    target = data_test.OpenStatus.values\n",
    "    T = []\n",
    "    for t in target:\n",
    "        if t == 'open':\n",
    "            T.append(1.)\n",
    "        else:\n",
    "            T.append(-1.)\n",
    "    print(roc_auc_score(T, preds))\n",
    "    \n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1456
    },
    "colab_type": "code",
    "id": "ZRdEFZFp7GTb",
    "outputId": "c4d420c3-341f-4371-f1c4-96d5b342093a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000       81\n",
      "0.500000 0.000000            2            2.0   1.0000   0.7311       98\n",
      "0.812846 1.125692            4            4.0  -1.0000   0.5555      110\n",
      "0.769143 0.725440            8            8.0  -1.0000   0.5734       38\n",
      "0.845550 0.921957           16           16.0   1.0000   0.6202      136\n",
      "0.812974 0.780397           32           32.0   1.0000   0.6439       93\n",
      "0.899824 0.986675           64           64.0   1.0000   0.5865       71\n",
      "0.894960 0.890097          128          128.0  -1.0000   0.4753       24\n",
      "0.893272 0.891584          256          256.0  -1.0000   0.5065       61\n",
      "0.917625 0.941978          512          512.0   1.0000   0.4394       33\n",
      "0.897855 0.878085         1024         1024.0   1.0000   0.4614      189\n",
      "0.879552 0.861248         2048         2048.0  -1.0000   0.4293       24\n",
      "0.856456 0.833361         4096         4096.0  -1.0000   0.5592       38\n",
      "0.839280 0.822103         8192         8192.0  -1.0000   0.4623       16\n",
      "0.806363 0.773447        16384        16384.0   1.0000   0.7311      296\n",
      "0.783823 0.761282        32768        32768.0  -1.0000   0.2689      101\n",
      "0.767485 0.767485        65536        65536.0   1.0000   0.7311      176 h\n",
      "0.759694 0.751903       131072       131072.0  -1.0000   0.4160       10 h\n",
      "0.751582 0.743471       262144       262144.0   1.0000   0.7311      352 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 7\n",
      "weighted example sum = 315000.000000\n",
      "weighted label sum = 252.000000\n",
      "average loss = 0.744282 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 34514333\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      187\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      126\n",
      "1.000614 2.001228            4            4.0  -1.0000   0.7311      516\n",
      "0.650463 0.300312            8            8.0   1.0000   0.7311      117\n",
      "0.649717 0.648972           16           16.0   1.0000   0.5482      155\n",
      "0.556571 0.463426           32           32.0   1.0000   0.5081       48\n",
      "0.704169 0.851766           64           64.0  -1.0000   0.5408      226\n",
      "0.692772 0.681375          128          128.0   1.0000   0.5609       86\n",
      "0.717330 0.741889          256          256.0  -1.0000   0.4951       83\n",
      "0.756197 0.795064          512          512.0   1.0000   0.7062      103\n",
      "0.765721 0.775244         1024         1024.0  -1.0000   0.3921       24\n",
      "0.748077 0.730434         2048         2048.0  -1.0000   0.2962      156\n",
      "0.745720 0.743363         4096         4096.0   1.0000   0.7311      167\n",
      "0.751567 0.757414         8192         8192.0  -1.0000   0.4614       45\n",
      "0.750410 0.749253        16384        16384.0  -1.0000   0.4464       81\n",
      "0.750508 0.750605        32768        32768.0  -1.0000   0.5913       66\n",
      "0.749124 0.747741        65536        65536.0   1.0000   0.7311       72\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 70272\n",
      "passes used = 1\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.749839\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 7697580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7984637295639088\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Ina55A67GTe"
   },
   "source": [
    "n-граммы (n=2) - индикаторы того, что два слова встретились рядом. Из \"мама мыла раму\" получаем биграммы \"мама мыла\" и \"мыла раму\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1491
    },
    "colab_type": "code",
    "id": "Vg6sQOnh7GTg",
    "outputId": "2af38293-37a6-4518-9d04-77d850b751f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000      158\n",
      "0.501991 0.003982            2            2.0   1.0000   0.7185      192\n",
      "0.769028 1.036065            4            4.0  -1.0000   0.5258      216\n",
      "0.788365 0.807701            8            8.0  -1.0000   0.5554       72\n",
      "0.853561 0.918757           16           16.0   1.0000   0.5926      268\n",
      "0.815435 0.777309           32           32.0   1.0000   0.6290      182\n",
      "0.899736 0.984037           64           64.0   1.0000   0.5476      138\n",
      "0.899076 0.898416          128          128.0  -1.0000   0.4850       44\n",
      "0.900915 0.902754          256          256.0  -1.0000   0.5106      118\n",
      "0.919717 0.938519          512          512.0   1.0000   0.4590       62\n",
      "0.894198 0.868679         1024         1024.0   1.0000   0.4761      374\n",
      "0.874036 0.853875         2048         2048.0  -1.0000   0.4419       44\n",
      "0.848005 0.821974         4096         4096.0  -1.0000   0.5279       72\n",
      "0.832330 0.816654         8192         8192.0  -1.0000   0.4895       28\n",
      "0.799748 0.767167        16384        16384.0   1.0000   0.7311      588\n",
      "0.771801 0.743855        32768        32768.0  -1.0000   0.2689      198\n",
      "0.758017 0.758017        65536        65536.0   1.0000   0.7311      348 h\n",
      "0.748931 0.739845       131072       131072.0  -1.0000   0.4163       16 h\n",
      "0.742015 0.735099       262144       262144.0   1.0000   0.7311      700 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 7\n",
      "weighted example sum = 315000.000000\n",
      "weighted label sum = 252.000000\n",
      "average loss = 0.735132 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 67768757\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      370\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      248\n",
      "1.000416 2.000831            4            4.0  -1.0000   0.7311     1028\n",
      "0.726774 0.453133            8            8.0   1.0000   0.7311      230\n",
      "0.611760 0.496745           16           16.0   1.0000   0.7288      306\n",
      "0.530342 0.448924           32           32.0   1.0000   0.5067       92\n",
      "0.677202 0.824062           64           64.0  -1.0000   0.4670      448\n",
      "0.679827 0.682452          128          128.0   1.0000   0.5748      168\n",
      "0.680356 0.680885          256          256.0  -1.0000   0.5740      162\n",
      "0.712045 0.743733          512          512.0   1.0000   0.7311      202\n",
      "0.728470 0.744896         1024         1024.0  -1.0000   0.3969       44\n",
      "0.714591 0.700711         2048         2048.0  -1.0000   0.3404      308\n",
      "0.720521 0.726451         4096         4096.0   1.0000   0.7199      330\n",
      "0.728133 0.735746         8192         8192.0  -1.0000   0.4562       86\n",
      "0.733180 0.738227        16384        16384.0  -1.0000   0.4794      158\n",
      "0.736419 0.739658        32768        32768.0  -1.0000   0.5624      128\n",
      "0.735185 0.733952        65536        65536.0   1.0000   0.7311      140\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 70272\n",
      "passes used = 1\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.736169\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 15114088\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.804926206271975\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWsWp25t7GTj"
   },
   "source": [
    "k-skip-n-граммы - как n-граммы, но разрешаем словам быть отдаленными друг от друга не больше, чем на k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1525
    },
    "colab_type": "code",
    "id": "D3EXDeI67GTm",
    "outputId": "e0d77434-cff6-48ec-f8f5-8cb18e11df8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "Generating 2-skips for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000      309\n",
      "0.598903 0.197807            2            2.0   1.0000   0.6354      377\n",
      "0.813193 1.027482            4            4.0  -1.0000   0.5188      425\n",
      "0.827788 0.842383            8            8.0  -1.0000   0.5387      137\n",
      "0.878166 0.928544           16           16.0   1.0000   0.5696      529\n",
      "0.833454 0.788743           32           32.0   1.0000   0.6141      357\n",
      "0.919097 1.004739           64           64.0   1.0000   0.5475      269\n",
      "0.925038 0.930980          128          128.0  -1.0000   0.4903       81\n",
      "0.922979 0.920921          256          256.0  -1.0000   0.4998      229\n",
      "0.931385 0.939790          512          512.0   1.0000   0.4615      117\n",
      "0.903010 0.874635         1024         1024.0   1.0000   0.4652      741\n",
      "0.888596 0.874181         2048         2048.0  -1.0000   0.4493       81\n",
      "0.858703 0.828809         4096         4096.0  -1.0000   0.5026      137\n",
      "0.841166 0.823629         8192         8192.0  -1.0000   0.4816       49\n",
      "0.809038 0.776910        16384        16384.0   1.0000   0.7311     1169\n",
      "0.778904 0.748770        32768        32768.0  -1.0000   0.2689      389\n",
      "0.765945 0.765945        65536        65536.0   1.0000   0.7311      689 h\n",
      "0.755040 0.744135       131072       131072.0  -1.0000   0.4247       25 h\n",
      "0.747567 0.740094       262144       262144.0   1.0000   0.7311     1393 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 6\n",
      "weighted example sum = 270000.000000\n",
      "weighted label sum = 216.000000\n",
      "average loss = 0.739266 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 114285174\n",
      "Generating 2-grams for t namespaces.\n",
      "Generating 2-skips for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      733\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      489\n",
      "1.000491 2.000982            4            4.0  -1.0000   0.7311     2049\n",
      "0.657112 0.313733            8            8.0   1.0000   0.7311      453\n",
      "0.500794 0.344476           16           16.0   1.0000   0.7164      605\n",
      "0.506039 0.511284           32           32.0   1.0000   0.4979      177\n",
      "0.681006 0.855974           64           64.0  -1.0000   0.6381      889\n",
      "0.664311 0.647617          128          128.0   1.0000   0.5470      329\n",
      "0.681359 0.698407          256          256.0  -1.0000   0.5694      317\n",
      "0.714270 0.747180          512          512.0   1.0000   0.7311      397\n",
      "0.724619 0.734969         1024         1024.0  -1.0000   0.4088       81\n",
      "0.719654 0.714688         2048         2048.0  -1.0000   0.3190      609\n",
      "0.725633 0.731613         4096         4096.0   1.0000   0.6793      653\n",
      "0.732191 0.738748         8192         8192.0  -1.0000   0.4654      165\n",
      "0.736435 0.740680        16384        16384.0  -1.0000   0.4838      309\n",
      "0.740426 0.744416        32768        32768.0  -1.0000   0.5634      249\n",
      "0.740818 0.741211        65536        65536.0   1.0000   0.7311      273\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 70272\n",
      "passes used = 1\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.741549\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 29736304\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8020425498436563\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 --skips t2 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1545
    },
    "colab_type": "code",
    "id": "YQNfl4T67GTq",
    "outputId": "1b9cd04a-9dc6-41d3-fa7b-43a87d4d1975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x560b42dd2000 @  0x7fe460ed0001 0x7fe460a6cb5f 0x7fe460a7aa21 0x7fe460b1de00 0x7fe460b0bbe3 0x7fe460b13395 0x7fe460b13c44 0x560b40ba7237 0x560b40ba6a8b 0x7fe46008bb97 0x560b40ba705a\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000      158\n",
      "0.501991 0.003982            2            2.0   1.0000   0.7185      192\n",
      "0.768823 1.035654            4            4.0  -1.0000   0.5257      216\n",
      "0.788250 0.807676            8            8.0  -1.0000   0.5554       72\n",
      "0.852059 0.915868           16           16.0   1.0000   0.5925      268\n",
      "0.814879 0.777699           32           32.0   1.0000   0.6291      182\n",
      "0.897638 0.980397           64           64.0   1.0000   0.5502      138\n",
      "0.897445 0.897252          128          128.0  -1.0000   0.4850       44\n",
      "0.898531 0.899617          256          256.0  -1.0000   0.5115      118\n",
      "0.919904 0.941277          512          512.0   1.0000   0.4604       62\n",
      "0.893383 0.866862         1024         1024.0   1.0000   0.4641      374\n",
      "0.874990 0.856597         2048         2048.0  -1.0000   0.4413       44\n",
      "0.846852 0.818714         4096         4096.0  -1.0000   0.5371       72\n",
      "0.830443 0.814034         8192         8192.0  -1.0000   0.4929       28\n",
      "0.796314 0.762186        16384        16384.0   1.0000   0.7311      588\n",
      "0.767529 0.738743        32768        32768.0  -1.0000   0.2689      198\n",
      "0.752728 0.752728        65536        65536.0   1.0000   0.7311      348 h\n",
      "0.742912 0.733097       131072       131072.0  -1.0000   0.4265       16 h\n",
      "0.733790 0.724669       262144       262144.0   1.0000   0.7311      700 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 7\n",
      "weighted example sum = 315000.000000\n",
      "weighted label sum = 252.000000\n",
      "average loss = 0.725734 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 67768757\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "tcmalloc: large alloc 1073741824 bytes == 0x5593238be000 @  0x7fa131a91001 0x7fa13162db5f 0x7fa13163ba21 0x7fa1316dee00 0x7fa1316ccbe3 0x7fa1316d4395 0x7fa1316d4c44 0x559321ed5237 0x559321ed4a8b 0x7fa130c4cb97 0x559321ed505a\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      370\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      248\n",
      "1.010778 2.021555            4            4.0  -1.0000   0.7311     1028\n",
      "0.660963 0.311149            8            8.0   1.0000   0.7311      230\n",
      "0.535013 0.409063           16           16.0   1.0000   0.6425      306\n",
      "0.523252 0.511491           32           32.0   1.0000   0.4812       92\n",
      "0.690913 0.858574           64           64.0  -1.0000   0.5924      448\n",
      "0.662273 0.633633          128          128.0   1.0000   0.5510      168\n",
      "0.702459 0.742645          256          256.0  -1.0000   0.5019      162\n",
      "0.721151 0.739842          512          512.0   1.0000   0.7311      202\n",
      "0.731540 0.741929         1024         1024.0  -1.0000   0.4013       44\n",
      "0.713196 0.694851         2048         2048.0  -1.0000   0.3860      308\n",
      "0.723218 0.733240         4096         4096.0   1.0000   0.7182      330\n",
      "0.723556 0.723894         8192         8192.0  -1.0000   0.4688       86\n",
      "0.724842 0.726127        16384        16384.0  -1.0000   0.4644      158\n",
      "0.727341 0.729841        32768        32768.0  -1.0000   0.5632      128\n",
      "0.727127 0.726912        65536        65536.0   1.0000   0.7311      140\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 70272\n",
      "passes used = 1\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.727744\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 15114088\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.811472812139381\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 -b 28 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlJz_9ly7GTu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "vw_tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
