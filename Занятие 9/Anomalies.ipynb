{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск аномалий. Часть 1.\n",
    "\n",
    "## Через визуализацию\n",
    "\n",
    "https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "\n",
    "## Box plot (ящик с усами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from matplotlib import pylab as plt\n",
    "%pylab inline\n",
    "\n",
    "boston = load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "columns = boston.feature_names\n",
    "boston_df = pd.DataFrame(boston.data)\n",
    "boston_df.columns = columns\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=boston_df['DIS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(boston_df['INDUS'], boston_df['TAX'])\n",
    "ax.set_xlabel('Proportion of non-retail business acres per town')\n",
    "ax.set_ylabel('Full-value property-tax rate per $10,000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-score\n",
    "\n",
    "Стандартизованная оценка (z-оценка, англ. : Standard score, z-score) - это мера относительного разброса наблюдаемого или измеренного значения, которая показывает сколько стандартных отклонений составляет его разброс относительного среднего значения.\n",
    "\n",
    "**Интуиция.**\n",
    "Вычисляя Z-score, мы масштабируем и центрируем данные и смотрим на точки, которые находятся далеко от 0. Точки, которые достаточно далеко от 0, считаются выбросами. В большинстве случаев используется порог 3 или -3, т.е. если Z-score больше 3 или меньше -3, то точка считается выбросом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(boston_df))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "print(np.where(z > 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый массив - список номеров строк, второй - номеров столбцов с выбросами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z[55][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQR\n",
    "\n",
    "IQR (интерквартильный размах) = Q3 - Q1, где Q1, Q3 - 25%- и 75%- квантили распределения соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = boston_df.quantile(0.25)\n",
    "Q3 = boston_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем аутлаеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston_df < (Q1 - 1.5 * IQR)) | (boston_df > (Q3 + 1.5 * IQR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Удаление выбросов\n",
    "\n",
    "## Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df_o = boston_df[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df.shape, boston_df_o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df_o1 = boston_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df_out = boston_df_o1[~((boston_df_o1 < (Q1 - 1.5 * IQR)) |(boston_df_o1 > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удалять или корректировать выбросы?\n",
    "\n",
    "Это зависит от каждой конкретной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление выбросов, основанное на нормальном распределении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "arr = [10, 386, 479, 627, 20, 523, 482, 483, 542, 699, 535, 617, 577, 471, 615, 583, 441, 562, 563, 527, 453, 530, 433, 541, 585, 704, 443, 569, 430, 637, 331, 511, 552, 496, 484, 566, 554, 472, 335, 440, 579, 341, 545, 615, 548, 604, 439, 556, 442, 461, 624, 611, 444, 578, 405, 487, 490, 496, 398, 512, 422, 455, 449, 432, 607, 679, 434, 597, 639, 565, 415, 486, 668, 414, 665, 763, 557, 304, 404, 454, 689, 610, 483, 441, 657, 590, 492, 476, 437, 483, 529, 363, 711, 543]\n",
    "\n",
    "elements = numpy.array(arr)\n",
    "\n",
    "mean = numpy.mean(elements, axis=0)\n",
    "sd = numpy.std(elements, axis=0)\n",
    "\n",
    "final_list = [x for x in arr if (x > mean - 2 * sd) or (x < mean + 2 * sd)]\n",
    "final_list = [x for x in final_list if (x < mean + 2 * sd)]\n",
    "len(arr), len(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Поработаем с Титаником. Найдите выбросы в каждом столбце (попробуйте наибольшее число из описанных способов).\n",
    "\n",
    "Изучите найденные выбросы. Подумайте, стоит ли их удалять?\n",
    "\n",
    "Обучите любой алгоритм на исходных данных с выбросами. Затем удалите те выбросы, которые решили удалить и заново обучите этот же алгоритм. Как удаление выбросов повлияло на качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation forest\n",
    "\n",
    "Сгенерируем данные и посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libaries ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import savefig\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# Generating data ----\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Generating training data \n",
    "X_train = 0.2 * rng.randn(1000, 2)\n",
    "X_train = np.r_[X_train + 3, X_train]\n",
    "X_train = pd.DataFrame(X_train, columns = ['x1', 'x2'])\n",
    "\n",
    "# Generating new, 'normal' observation\n",
    "X_test = 0.2 * rng.randn(200, 2)\n",
    "X_test = np.r_[X_test + 3, X_test]\n",
    "X_test = pd.DataFrame(X_test, columns = ['x1', 'x2'])\n",
    "\n",
    "# Generating outliers\n",
    "X_outliers = rng.uniform(low=-1, high=5, size=(50, 2))\n",
    "X_outliers = pd.DataFrame(X_outliers, columns = ['x1', 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting generated data ----\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Data\")\n",
    "\n",
    "p1 = plt.scatter(X_train.x1, X_train.x2, c='white',\n",
    "                 s=20*4, edgecolor='k')\n",
    "p2 = plt.scatter(X_test.x1, X_test.x2, c='green',\n",
    "                 s=20*4, edgecolor='k')\n",
    "p3 = plt.scatter(X_outliers.x1, X_outliers.x2, c='red',\n",
    "                s=20*4, edgecolor='k')\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.xlim((-2, 5))\n",
    "plt.ylim((-2, 5))\n",
    "plt.legend([p1, p2, p3],\n",
    "           [\"training observations\",\n",
    "            \"new regular obs.\", \"new abnormal obs.\"],\n",
    "           loc=\"lower right\")\n",
    "\n",
    "# saving the figure\n",
    "plt.savefig('generated_data.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим IsolationForest и сделаем предсказание на наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest ----\n",
    "\n",
    "# training the model\n",
    "clf = IsolationForest(max_samples=100, contamination = 0.1, random_state=rng)\n",
    "clf.fit(X_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new, 'normal' observations\n",
    "print(\"Accuracy:\", len(y_pred_test[y_pred_test==1])/len(y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "print(\"Accuracy:\", len(y_pred_outliers[y_pred_outliers==-1])/len(y_pred_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем найденные выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the outliers ----\n",
    "\n",
    "# adding the predicted label\n",
    "X_outliers = X_outliers.assign(y = y_pred_outliers)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Outlier Inspection\")\n",
    "\n",
    "p1 = plt.scatter(X_train.x1, X_train.x2, c='white',\n",
    "                 s=20*4, edgecolor='k')\n",
    "p2 = plt.scatter(X_outliers.loc[X_outliers.y == -1, ['x1']], \n",
    "                 X_outliers.loc[X_outliers.y == -1, ['x2']], \n",
    "                 c='red', s=20*4, edgecolor='k')\n",
    "p3 = plt.scatter(X_outliers.loc[X_outliers.y == 1, ['x1']], \n",
    "                 X_outliers.loc[X_outliers.y == 1, ['x2']], \n",
    "                 c='green', s=20*4, edgecolor='k')\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.xlim((-2, 5))\n",
    "plt.ylim((-2, 5))\n",
    "plt.legend([p1, p2, p3],\n",
    "           [\"training observations\",\n",
    "            \"detected outliers\", \n",
    "            \"detected regular obs.\"],\n",
    "           loc=\"lower right\")\n",
    "\n",
    "# saving the figure\n",
    "plt.savefig('outlier_inspection.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поработаем с датасетом glass https://archive.ics.uci.edu/ml/datasets/Glass+Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# read flash.dat to a list of lists\n",
    "datContent = [i.strip().split() for i in open(\"glass.data\").readlines()]\n",
    "datContent = [elem[0].split(',') for elem in datContent]\n",
    "\n",
    "df = pd.DataFrame(datContent, columns=['id','f1','f2','f3','f4','f5','f6','f7','f8','f9','f10'])\n",
    "del df['id']\n",
    "df = df.astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = df['f10']\n",
    "del X['f10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите на качество логистической регрессии на этих данных на кросс-валидации, используйте функцию cross_val_score и 3 фолда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалите выбросы. Предположим, что их не более 10% в наших данных, т.е. используйте IsolationForest с параметром contamination=0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставьте только точки, которые не являются выбросами по мнению IsolationForest и заново обучите логистическую регрессию на кросс-валидации. Как изменилось качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
