{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ноутбук составлен по мотивам https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_english/topic04_linear_models/topic4_linear_models_part4_good_bad_logit_movie_reviews_XOR.ipynb\n",
    "\n",
    "# Логистическая регрессия. Пример.\n",
    "\n",
    "Поработаем с данными IMDB movie reviews.\n",
    "\n",
    "**Скачайте данные по ссылке https://www.dropbox.com/s/d9fadkx9vi3kw9o/aclImdb_v1.tar.gz?dl=0**\n",
    "\n",
    "В этом датасете 25000 отзывов на фильмы: 12500 положительных и 12500 отрицательных. Мы хотим решить задачу классификации отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "PATH_TO_IMDB = './aclImdb'\n",
    "\n",
    "reviews_train = load_files(os.path.join(PATH_TO_IMDB, \"train\"),\n",
    "                           categories=['pos', 'neg'])\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "\n",
    "reviews_test = load_files(os.path.join(PATH_TO_IMDB, \"test\"),\n",
    "                          categories=['pos', 'neg'])\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))\n",
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для генерации признаков используем CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How it works](CV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How it works](CV2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(text_train)\n",
    "\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на слова в получившимся словаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.get_feature_names()[:50])\n",
    "print(cv.get_feature_names()[50000:50050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем предложения индексами слов из словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train[19723])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[19723].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучим логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(solver='lbfgs', n_jobs=-1, random_state=7)\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.score(X_train, y_train), logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нарисуем наибольшие по модулю веса**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_coefficients(classifier, feature_names, n_features=25):\n",
    "\n",
    "    coef = classifier.coef_.ravel()\n",
    "    positive_coefficients = np.argsort(coef)[-n_features:]\n",
    "    negative_coefficients = np.argsort(coef)[:n_features]\n",
    "    all_coefs = np.hstack([negative_coefficients, positive_coefficients])\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[all_coefs]]\n",
    "    plt.bar(np.arange(2*n_features), coef[all_coefs], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1+2*n_features), feature_names[all_coefs], rotation=60, ha=\"right\")\n",
    "    \n",
    "visualize_coefficients(logit, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем параметр регуляризации в логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_logit = make_pipeline(CountVectorizer(),\n",
    "                           LogisticRegression(solver='lbfgs', random_state=123))\n",
    "\n",
    "pipe_logit.fit(text_train, y_train)\n",
    "pipe_logit.score(text_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'logisticregression__C': np.logspace(-5, 0, 6)}\n",
    "grid_logit = GridSearchCV(pipe_logit, \n",
    "                          param_grid, \n",
    "                          return_train_score=True, \n",
    "                          n_jobs=1,\n",
    "                          cv=3)\n",
    "\n",
    "grid_logit.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit.best_params_, grid_logit.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты подбора параметра по кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grid_logit.param_grid['logisticregression__C'], grid_logit.cv_results_['mean_train_score'],\n",
    "        color='green', label='train')\n",
    "plt.plot(grid_logit.param_grid['logisticregression__C'], grid_logit.cv_results_['mean_test_score'],\n",
    "        color='red', label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit.score(text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нарисуем ROC-кривую и вычислим ROC-AUC на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = grid_logit.predict_proba(text_test)[::,1]\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, pred)\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, pred)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"test_data, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "\n",
    "Нарисуйте на одном графике ROC-кривые для train и для test. Добавьте на график значения ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нарисуем матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    " \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_test = grid_logit.predict(text_test)\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test, ans_test), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "\n",
    "Добавим в условие задачи, что мы хотим, чтобы как можно меньше положительных отзывов алгоритм предсказывал, как отрицательные. \n",
    "Для этого подберите порог вероятности таким образом, чтобы False Negative элементов на тесте было не больше 1000.\n",
    "\n",
    "Нарисуйте полученную матрицу ошибок.\n",
    "\n",
    "Выведите значение ROC-AUC.\n",
    "\n",
    "Выведите значения precision, recall и f1-score (все они находятся в sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Когда линейные модели работают плохо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How it works](XOR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим данные для задачи XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(200, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая рисует разделяющую границу, проведенную классификатором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, plot_title):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "    clf.fit(X, y)\n",
    "    # plot the decision function for each datapoint on the grid\n",
    "    Z = clf.predict_proba(np.vstack((xx.ravel(), yy.ravel())).T)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    image = plt.imshow(Z, interpolation='nearest',\n",
    "                           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                           aspect='auto', origin='lower', cmap=plt.cm.PuOr_r)\n",
    "    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
    "                               linetypes='--')\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    plt.colorbar(image)\n",
    "    plt.title(plot_title, fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(LogisticRegression(solver='lbfgs'), X, y,\n",
    "              \"Logistic Regression, XOR problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что задача решена плохо. Попробуем добавить в качестве признаков полиномиальные признаки степени 2.\n",
    "\n",
    "Теперь у нас будут признаки не только $(1, x_1, x_2)$, но и $1, x_1, x_2, x_1^2, x_1x_2, x_2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logit_pipe = Pipeline([('poly', PolynomialFeatures(degree=2)), \n",
    "                       ('logit', LogisticRegression(solver='lbfgs' ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit_pipe, X, y,\n",
    "              \"Logistic Regression + quadratic features. XOR problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Таким образом, при добавлении новых нелинейных признаков с помощью линейного классификатора можно решить линейно неразделимую задачу.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача классификации: есть ли у человека болезнь сердца.\n",
    "\n",
    "Вам необходимо предсказать, болен пациент или здоров (target) и добиться наиболее высокого качества предсказания (accuracy). Можно использовать любые методы работы с данными (ограничение: классификатор - логистическая регрессия).\n",
    "\n",
    "Обучение необходимо провести на данных heart_train.csv, а итоговое качество модели проверяется на heart_test.csv.\n",
    "\n",
    "В качестве результата домашнего задания вам необходимо прислать код вашей финальной модели и csv-файл с предсказаниями на данных heart_test.csv. Метрика качества - accuracy.\n",
    "\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "age - age in years\n",
    "\n",
    "sex - (1 = male; 0 = female)\n",
    "\n",
    "cpchest - pain type\n",
    "\n",
    "trestbpsresting - blood pressure (in mm Hg on admission to the hospital)\n",
    "\n",
    "cholserum - cholestoral in mg/dl\n",
    "\n",
    "fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "\n",
    "restecg - resting electrocardiographic results\n",
    "\n",
    "thalach - maximum heart rate achieved\n",
    "\n",
    "exang - exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "oldpeak - ST depression induced by exercise relative to rest\n",
    "\n",
    "slope - the slope of the peak exercise ST segment\n",
    "\n",
    "ca - number of major vessels (0-3) colored by flourosopy\n",
    "\n",
    "thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "\n",
    "target - 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"heart_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с \"бездумного\" машинного обучения. Разбейте выборку на тренировочную и валидационную части (20% данных на валидацию), обучите логистическую регрессию с дефолтными параметрами и выведите на экран метрики качества на train и на test.\n",
    "\n",
    "Постройте ROC-кривую.\n",
    "\n",
    "Визуализируйте матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь серьёзно подойдем к задаче.\n",
    "\n",
    "### Шаги, которые нужно сделать:\n",
    "\n",
    "1) Разведочный анализ данных (построение графиков, нахождение корреляций)\n",
    "\n",
    "2) Различные способы кодирования данных\n",
    "\n",
    "3) Генерация новых признаков (полиномиальные признаки, другие функции от признаков).\n",
    "\n",
    "4*) Очистка данных (возможно, в данных есть аномальные значения, которые будут видны при визуализации), с ними надо поработать, можно удалить\n",
    "\n",
    "5) Подбор гиперпараметров логистической регрессии по кросс-валидации\n",
    "\n",
    "6) Проверка модели на переобученность\n",
    "\n",
    "7) Построение ROC-кривой и вычисление ROC-AUC на тренировочной и тестовой выборках. Вычисление accuracy, precision, recall, f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
