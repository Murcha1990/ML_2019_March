{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающие деревья и решающие леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модельную задачу регрессии. Объектами будут являться точки на плоскости (т.е. каждый объект описывается 2 признаками), целевая переменная — расстояние от объекта до точки (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем вспомогательную функцию, которая будет возвращать решетку для дальнейшей красивой визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.normal(size=(100, 2))\n",
    "data_y = (data_x[:, 0] ** 2 + data_x[:, 1] ** 2) ** 0.5\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим дерево на сгенерированных данных и предскажем ответы для каждой точки решетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "xx, yy = get_grid(data_x)\n",
    "print(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Сейчас мы сгенерировали 100 точек из нормального распределения и обучили решающее дерево на них. Сгенерируйте 300 точек из нормального распределения, обучите на них дерево и выведите на экран результат (как на картинке выше).\n",
    "\n",
    "Сгенерированные точки и расстояние до точек сохраните в массивы data_x300, data_y300, для обучения и предсказания используйте эти массивы.\n",
    "\n",
    "Улучшилось ли предсказание алгоритма на решётке? (т.е. стала ли раскраска всей плоскости более правильной?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернёмся к исходным данным (100 точек).\n",
    "\n",
    "Посмотрим как будут выглядеть разделяющая поверхность в зависимости от \n",
    "- минимального количества объектов в листе\n",
    "- максимальной глубины дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "for i, max_depth in enumerate([1, 2, 4, 6]):\n",
    "    for j, min_samples_leaf in enumerate([1, 5, 10, 15]):\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        clf.fit(data_x, data_y)\n",
    "        xx, yy = get_grid(data_x)\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "        plt.subplot2grid((4, 4), (i, j))\n",
    "        plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='spring')\n",
    "        plt.title('max_depth=' + str(max_depth) + ', min_samples_leaf: ' + str(min_samples_leaf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как влияет увеличение максимальной глубины и/или уменьшение минимального количества объектов выборки в листе на качество на обучающей выборке? на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Неустойчивость решающих деревьев\n",
    "\n",
    "Решающие деревья — это алгоритмы, неустойчивые к изменениям обучающей выборки, т.е. при малейших её изменениях итоговый классификатор может радикально измениться.\n",
    "Посмотрим, как будет меняться структура дерева при обучении на разных 90%-х подвыборках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    indices = np.random.randint(data_x.shape[0], size=int(data_x.shape[0] * 0.9))\n",
    "    clf.fit(data_x[indices], data_y[indices])\n",
    "    xx, yy = get_grid(data_x)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество дерева в зависимости от параметров на одном из стандартных наборов данных - Бостонском датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = data.data\n",
    "y_full = data.target\n",
    "\n",
    "print(X_full[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- разобъём все данные на train и test\n",
    "- будем оценивать качество алгоритма по кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X_full, y_full, test_size=100, \n",
    "                                        random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cv = KFold(X.shape[0], shuffle=True, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regr = DecisionTreeRegressor(random_state=241)\n",
    "print(-cross_val_score(regr, X, y, cv=cv, \n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Метрика MSЕ имеет не ограничена сверху. Поэтому для оценки качества алгоритма можно также пользоваться метрикой R2 (коэффициент детерминации), так как он не превышает 1 (и чем ближе к 1, тем лучше).\n",
    "\n",
    "Выведите на экран значение R2 алгоритма ('r2')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения качества модели при различных наборах параметров или для сравнения моделей на одном датасете можно использовать, как и раньше, MSE.\n",
    "\n",
    "Будем подбирать параметры решающего дерева по сетке с целью увеличить качество алгоритма. Будем подбирать значения max_features и max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(DecisionTreeRegressor(random_state=241),\n",
    "                  param_grid={'max_features': [None, 'log2', 'sqrt'], \n",
    "                              'max_depth': [2, 4, 6, 8, 10, 20, 50]},\n",
    "                  cv=cv,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Теперь попробуем одновременно подбирать значения max_features, max_depth и min_samples_leaf. Ищите min_samples_leaf в диапазоне range(1,20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как в данной задаче зависит качество алгоритма от количества параметров, которые мы оптимизируем?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающие деревья для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем данные. Два класса будут сгенерированы из двух нормальных распределений с разными средними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "a = np.random.normal(loc=0, size=(n, 2))\n",
    "b = np.random.normal(loc=2, size=(n, 2))\n",
    "\n",
    "data_x = np.vstack([a, b])\n",
    "data_y = np.hstack([np.zeros(n), np.ones(n)])\n",
    "\n",
    "scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='autumn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разделить эти два класса, обучив решающее дерево. Визуализируем полученную границу разделения класссов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=7)\n",
    "clf.fit(data_x, data_y)\n",
    "xx, yy = get_grid(data_x)\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "pcolormesh(xx, yy, predicted, cmap='autumn')\n",
    "scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=150, cmap='autumn', alpha=0.7)\n",
    "ylim([yy.min(),yy.max()])\n",
    "xlim([xx.min(),xx.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "По аналогии с GridSearchCV для DecisionTreeRegressor используйте GridSearchCV для DecisionTreeClassifier, чтобы посмотреть, как различные параметры влияют на качество классификации.\n",
    "\n",
    "возьмите cv=5 (число фолдов), параметры 'min_samples_leaf': [1, 3, 7, 20], 'max_depth': [2, 3, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=2, min_samples_leaf=20)\n",
    "clf.fit(data_x, data_y)\n",
    "xx, yy = get_grid(data_x)\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "pcolormesh(xx, yy, predicted, cmap='autumn')\n",
    "scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=150, cmap='autumn', alpha=0.7)\n",
    "ylim([yy.min(),yy.max()])\n",
    "xlim([xx.min(),xx.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Решающий лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какое качество можно получить при использовании решающего леса. Будем делать предсказания на Boston dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor()\n",
    "print(-cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=10)\n",
    "print(-cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=100)\n",
    "print(-cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=300, n_jobs=-1)\n",
    "print(-cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=500, n_jobs=-1)\n",
    "print(-cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
    "print(-cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "Постройте график качества классификации на кросс-валидации в зависимости от числа деревьев.\n",
    "\n",
    "На каждой итерации цикла обучайте регрессор командой regr = ... и добавляйте в список Scores число cross_val_score:\n",
    "Scores.append(cross_val_score(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "Ntrees = np.arange(5,120,20)\n",
    "Scores = []\n",
    "\n",
    "for elem in tqdm(Ntrees):\n",
    "    #Your code here\n",
    "    regr = ...\n",
    "    Scores.append(...)\n",
    "    \n",
    "plot(Scores)\n",
    "xticks(arange(len(Ntrees)), Ntrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "Поработайте с датасетом wine_data (в каждой строке этого датасета содержится информация о бутылках вина одного из трёх видов: в первой колонке - вид вина (1, 2 или 3), в колонках 1-13 - свойства вина). \n",
    "\n",
    "1) Посчитайте качество DecisionTreeClassifier и RandomForestClassifier на кросс-валидации.\n",
    "\n",
    "2*) Попробуйте уменьшить число признаков с помощью какого-либо метода отбора признаков (http://scikit-learn.org/stable/modules/feature_selection.html). Добейтесь увеличения качества RandomForestClassifier на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wine_data.csv', header=None)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[0].as_matrix()\n",
    "X = data.drop(0, axis=1).as_matrix()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "Примените к BostonDataset линейную регрессию. Сравните ее качество на кросс-валидации с качеством DecisionTreeRegressor и RandomForestRegressor.\n",
    "Какой алгоритм работает лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = #your algroithm here\n",
    "cv = KFold(data_x.shape[0], shuffle=True, random_state=241)\n",
    "\n",
    "print(cross_val_score(regr, data_x, data_y, cv=cv, scoring='neg_mean_squared_error').mean())\n",
    "\n",
    "#Try other algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
